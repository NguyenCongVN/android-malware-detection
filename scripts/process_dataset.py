import argparse
import joblib as J
import multiprocessing
import networkx as nx
import sys
import traceback
from androguard.misc import AnalyzeAPK
import pandas as pd

from pathlib import Path

def get_api_list(file):
	apis = open(file).readlines()
	return {x.strip(): i for i, x in enumerate(apis)}

def get_opcode_mapping():
	mapping = {x:i for i,x in enumerate(['nop', 'mov', 'return',
	 'const', 'monitor', 'check-cast', 'instanceof', 'new',
	 'fill', 'throw', 'goto/switch', 'cmp','if', 'unused',
	 'arrayop', 'instanceop', 'staticop', 'invoke',
	 'unaryop', 'binop', 'inline'])}
	mapping['invalid'] = -1;
	return mapping

opcode_mapping = get_opcode_mapping()

def get_instruction_type(instr):
	value = instr.get_op_value()
	if 0x00 == value:
		return 'nop'
	elif 0x01 <= value <= 0x0D:
		return 'mov'
	elif 0x0E <= value <= 0x11:
		return 'return'
	elif 0x12 <= value <= 0x1C:
		return 'const'
	elif 0x1D <= value <= 0x1E:
		return 'monitor'
	elif 0x1F == value:
		return 'check-cast'
	elif 0x20 == value:
		return 'instanceof'
	elif 0x22 <= value <= 0x23:
		return 'new'
	elif 0x24 <= value <= 0x26:
		return 'fill'
	elif 0x27 == value:
		return 'throw'
	elif 0x28 <= value <= 0x2C:
		return 'goto/switch'
	elif 0x2D <= value <= 0x31:
		return 'cmp'
	elif 0x32 <= value <= 0x3D:
		return 'if'
	elif (0x3E <= value <= 0x43) or (value == 0x73) or (0x79 <= value <= 0x7A) or (0xE3 <= value <= 0xED):
		return 'unused'
	elif (0x44 <= value <= 0x51) or (value == 0x21):
		return 'arrayop'
	elif (0x52 <= value <= 0x5F) or (0xF2 <= value <= 0xF7):
		return 'instanceop'
	elif 0x60 <= value <= 0x6D:
		return 'staticop'
	elif (0x6E <= value <= 0x72) or (0x74 <= value <= 0x78) or (0xF0 == value) or (0xF8 <= value <= 0xFB):
		return 'invoke'
	elif 0x7B <= value <= 0x8F:
		return 'unaryop'
	elif 0x90 <= value <= 0xE2:
		return 'binop'
	elif 0xEE == value:
		return 'inline'
	else:
		return 'invalid'

def mapping_to_bitstring(mapping):
	max_len = len(opcode_mapping) - 1
	bitstring = ['0'] * max_len
	for index in mapping:
		bitstring[index] = '1'
	return ''.join(bitstring)

def process(source_file, dest_dir, api_list):
	try:
		file_name = source_file.stem
		_, _, dx = AnalyzeAPK(source_file)
		cg = dx.get_call_graph()
		mappings = {}
		for node in cg.nodes():
			mapping = {"ApiPackage": -1, "opcodes": set()}
			if node.is_external():
				name = '.'.join(map(str, node.full_name.split(';')[0][1:].split('/')[:-2]))
				index = api_list.get(name, -1)
				mapping["ApiPackage"] = index
			else:
				for instr in node.get_method().get_instructions():
					instruction_type = get_instruction_type(instr)
					instruction_id = opcode_mapping[instruction_type]
					if instruction_id >= 0:
						mapping["opcodes"].add(instruction_id)
			mapping["opcodes"] = mapping_to_bitstring(mapping["opcodes"])
			mappings[node] = mapping
		nx.set_node_attributes(cg, mappings)
		cg = nx.convert_node_labels_to_integers(cg)
		#nx.write_gml(cg, dest_dir/f'{file_name}.graph.bz2')
		nodes = pd.DataFrame.from_dict(dict(cg.nodes(data=True)), orient='index') 
		nodes = nodes.drop(columns=nodes.columns[nodes.columns == 'vm'])
		edges = pd.DataFrame.from_records(list(cg.edges()), columns=['src', 'dest'])
		dest_dir = dest_dir/f'{file_name}'
		dest_dir.mkdir(parents=True, exist_ok=True)
		nodes.to_parquet(dest_dir/'nodes.pqt')
		edges.to_parquet(dest_dir/'edges.pqt')
		print(f"Processed {source_file}")
	except:
		print(f"Error while processing {source_file}")
		traceback.print_exception(*sys.exc_info())
		return

if __name__ == '__main__':
	parser = argparse.ArgumentParser(description='Preprocess APK Dataset into Graphs')
	parser.add_argument('--source-dir', help='The directory containing apks', required=True)
	parser.add_argument('--dest-dir', help='The directory to store processed graphs', required=True)
	parser.add_argument('--api-list', help='The file containing the list of API packages', required=True)
	parser.add_argument('--override', help='Override existing processed files', action='store_true')
	parser.add_argument('--dry', help='Run without actual processing', action='store_true')
	parser.add_argument('--n-jobs', default=multiprocessing.cpu_count(), help='Number of jobs to be used for processing')
	args = parser.parse_args()
	source_dir = Path(args.source_dir)
	if not source_dir.exists():
		raise FileNotFoundError(f'{source_dir} not found')
	dest_dir = Path(args.dest_dir)
	if not dest_dir.exists():
		raise FileNotFoundError(f'{dest_dir} not found')
	api_list = Path(args.api_list)
	if not api_list.exists():
		raise FileNotFoundError(f'{api_list} not found')
	n_jobs = args.n_jobs
	if n_jobs < 2:
		print(f"n_jobs={n_jobs} is too less. Switching to number of CPUs in this machine instead")
		n_jobs = multiprocessing.cpu_count()
	api_list = get_api_list(api_list)
	files = [x for x in source_dir.iterdir() if x.is_file()]
	
	source_files = set([x.stem for x in files])
	dest_files = set(['.'.join(x.stem.split('.')[:-1]) for x in dest_dir.iterdir() if x.is_file()])
	unprocessed = [source_dir/f'{x}.apk' for x in source_files - dest_files]
	print(f"Only {len(unprocessed)} out of {len(source_files)} remain to be processed")
	if args.override:
		print(f"--override specified. Ignoring {len(source_files)-len(unprocessed)} processed files")
		unprocessed = [source_dir/f'{x}.apk' for x in source_files]
	print(f"Starting dataset processing with {n_jobs} Jobs")
	if not args.dry:
		J.Parallel(n_jobs=n_jobs)(J.delayed(process)(x, dest_dir, api_list) for x in unprocessed);
	print("DONE")
