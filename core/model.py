from typing import List, Tuple

import dgl
import pytorch_lightning as pl
import pytorch_lightning.metrics as metrics
import torch
import torch.nn.functional as F
from dgl.nn import Sequential
from dgl.nn.pytorch import SAGEConv, GATConv, edge_softmax
from torch import nn

from scripts.process_dataset import get_api_list
from .metrics import ROC_AUC
from .utils import readout_nodes


class GAT(nn.Module):
    def __init__(self,
                 num_layers: int,
                 in_dim: int,
                 num_hidden: int,
                 num_outputs: int,
                 heads: List[int],
                 activation,
                 feat_drop: float = 0,
                 attn_drop: float = 0,
                 negative_slope: float = 0.2,
                 residual: bool = True):
        super(GAT, self).__init__()
        self.num_layers = num_layers
        self.gat_layers = nn.ModuleList()
        self.activation = activation
        # input projection (no residual)
        self.gat_layers.append(GATConv(
            in_dim, num_hidden, heads[0],
            feat_drop, attn_drop, negative_slope, False, self.activation))
        # hidden layers
        for l in range(1, num_layers):
            # due to multi-head, the in_dim = num_hidden * num_heads
            self.gat_layers.append(GATConv(
                num_hidden * heads[l - 1], num_hidden, heads[l],
                feat_drop, attn_drop, negative_slope, residual, self.activation))
        # output projection
        self.gat_layers.append(GATConv(
            num_hidden * heads[-2], num_outputs, heads[-1],
            feat_drop, attn_drop, negative_slope, residual, None))

    def forward(self, g, inputs):
        h = inputs
        for l in range(self.num_layers):
            h = self.gat_layers[l](g, h).flatten(1)
        # output projection
        logits = self.gat_layers[-1](g, h).mean(1)
        return logits


class MalwareDetector(pl.LightningModule):
    def __init__(self,
                 input_dimension,
                 convolution_dimensions: List[int],
                 readout_weights: str = 'all',
                 readout_type: str = 'mean'
                 ):
        super().__init__()
        if readout_weights != 'internal' and readout_weights != 'external' and readout_weights != 'all':
            raise ValueError(f"aggregator_type must be one of 'internal', 'external or 'all'. Got '{readout_weights}'")
        self.save_hyperparameters()
        num_heads = 4
        num_out_heads = 6
        num_layers = 2
        heads = ([num_heads] * num_layers) + [num_out_heads]
        self.gat = GAT(num_layers=num_layers,
                       in_dim=input_dimension,
                       num_hidden=256,
                       num_outputs=64,
                       heads=heads,
                       activation=F.elu,
                       )
        '''
        self.convolution_layers = []
        for dimension in convolution_dimensions:
            self.convolution_layers.append(
                SAGEConv(input_dimension, dimension, aggregator_type='mean', activation=F.relu)
            )
            input_dimension = dimension
        self.convolution_layers = Sequential(*self.convolution_layers)
        self.last_dimension = input_dimension'''
        self.classify = nn.Linear(64, 1)
        self.loss_func = nn.BCEWithLogitsLoss()

        self.accuracy = metrics.Accuracy()
        self.recall = metrics.Recall(num_classes=1)
        self.f1 = metrics.FBeta(num_classes=1)
        self.precision_ = metrics.Precision(num_classes=1)
        self.auc_roc = ROC_AUC()

        self.api_list_length = len(get_api_list())

    def _process_api_package(self, g: dgl.DGLGraph) -> dgl.DGLGraph:
        nodes = torch.arange(len(g.nodes()), device=self.device)
        api_packages = g.ndata['api_package']
        dim_0 = nodes[torch.where(api_packages >= 0)].view(-1, 1)
        dim_1 = api_packages[torch.where(api_packages >= 0)].view(-1, 1)
        indices = torch.cat([dim_0, dim_1], dim=1).t()
        values = torch.ones(len(dim_0), device=self.device)
        size = torch.Size([len(g.nodes()), self.api_list_length])
        g.ndata['api_package'] = torch.sparse.ShortTensor(indices, values, size).to_dense().squeeze()
        return g

    def forward(self, g: dgl.DGLGraph) -> torch.Tensor:
        if len(g.ndata.keys()) > 1:
            if 'api_package' in g.ndata:
                g = self._process_api_package(g)
            if 'opcodes' in g.ndata:
                g.ndata['opcodes'] = g.ndata['opcodes'].squeeze()
            h = torch.cat([g.ndata[x] for x in g.ndata.keys() if x != 'ex'], dim=1).float()
        else:
            h = (g.in_degrees() + g.out_degrees()).view(-1, 1).float()
        h = self.gat(g, h)
        g.ndata['h'] = h
        '''h = self.convolution_layers.forward(g, h)
        g.ndata['h'] = h if len(self.convolution_layers) > 0 else h[0]
        del h'''
        args = ['weight']
        kwargs = {'bool_weights': True}
        if self.hparams.readout_weights == 'internal':
            g.ndata['weight'] = (1 - g.ndata['ex'].float())
        elif self.hparams.readout_weights == 'external':
            g.ndata['weight'] = (g.ndata['ex'].float())
        else:  # All
            args = []
            kwargs = {}
        # Calculate graph representation by averaging all the node representations.
        hg = readout_nodes(g, 'h', op=self.hparams.readout_type, *args, **kwargs)
        return self.classify(hg).squeeze()

    def training_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor], batch_idx: int) -> torch.Tensor:
        bg, label = batch
        prediction = self.forward(bg)
        loss = self.loss_func(prediction, label)
        self.log('train_loss', loss, on_step=True, on_epoch=True)
        return loss

    def validation_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor], batch_idx: int):
        bg, label = batch
        prediction = self.forward(bg)
        loss = self.loss_func(prediction, label)
        self.log('val_loss', loss, on_step=False, on_epoch=True)

    def test_step(self, batch: Tuple[dgl.DGLGraph, torch.Tensor], batch_idx: int):
        bg, label = batch
        prediction = self.forward(bg)
        logits = torch.sigmoid(prediction)
        _ = self.auc_roc(logits, label)
        test_metrics = {
            'test_loss': self.loss_func(prediction, label),
            'test_accuracy': self.accuracy(logits, label),
            'test_precision': self.precision_(logits, label),
            'test_recall': self.recall(logits, label),
            'test_f1': self.f1(logits, label),
        }
        self.log_dict(test_metrics, on_step=False, on_epoch=True)

    def configure_optimizers(self) -> torch.optim.Adam:
        optimizer = torch.optim.Adam(self.parameters(), lr=5e-3)
        return optimizer
