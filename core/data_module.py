import re
from pathlib import Path
from typing import List, Dict, Tuple, Union

import dgl
import pytorch_lightning as pl
import torch
from sklearn.model_selection import StratifiedShuffleSplit
from torch.utils.data import DataLoader

from core.dataset import MalwareDataset
from sklearn.utils import resample


def stratified_split_dataset(samples: List[str],
                             labels: Dict[str, int],
                             ratios: List[float]) -> Tuple[List, List, List]:
    if sum(ratios) != 1:
        raise Exception("Invalid ratios provided")
    train_ratio, val_ratio, test_ratio = ratios
    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_ratio, random_state=0)
    train_idx, test_idx = list(sss.split(samples, [labels[x] for x in samples]))[0]
    sss = StratifiedShuffleSplit(n_splits=1, test_size=val_ratio / (1 - test_ratio), random_state=0)
    test_list = [samples[x] for x in test_idx]
    train_list = [samples[x] for x in train_idx]
    train_idx, val_idx = list(sss.split(train_list, [labels[x] for x in train_list]))[0]
    train_list = [samples[x] for x in train_idx]
    val_list = [samples[x] for x in val_idx]
    return train_list, val_list, test_list


def balanced_split_dataset(samples: List[str],
                           labels: Dict[str, int],
                           ratios: List[float]) -> Tuple[List, List, List]:
    """
    Perform balanced split on binary classification dataset. We assume that labels are 1 and 0 (int)
    :param samples: List of samples
    :param labels: Mapping from samples to labels
    :return: List of splits containing training, validation and testing lists
    """
    label_values = list(labels.values())
    unique_labels = set(label_values)
    counts = {label: label_values.count(label) for label in unique_labels}
    sample_split = {label: [x for x in samples if labels[x] == label] for label in unique_labels}
    minority_class = min(sample_split, key=lambda k: counts[k])
    minority_count = counts[minority_class]
    for label in unique_labels:
        if label == minority_class:
            pass
        sample_split[label] = resample(sample_split[label], replace=False, n_samples=minority_count, random_state=0)
    samples_modified = sum(sample_split.values(), start=[])
    return stratified_split_dataset(samples_modified, labels, ratios)


def collate(samples: List[Tuple[dgl.DGLGraph, int]]) -> (dgl.DGLGraph, torch.Tensor):
    graphs, labels = map(list, zip(*samples))
    batched_graph = dgl.batch(graphs)
    labels = torch.tensor(labels)
    return batched_graph, labels.float()


class MalwareDataModule(pl.LightningDataModule):

    def __init__(self, data_dir: Union[str, Path], batch_size: int, split_ratios: List[float], balanced: bool = False):
        super().__init__()
        self.split_ratios = split_ratios
        self.data_dir = data_dir
        self.batch_size = batch_size
        self.splitter = balanced_split_dataset if balanced else stratified_split_dataset

    def get_samples(self) -> Tuple[List[str], Dict[str, int]]:
        base_path = Path(self.data_dir)
        labels_dict = {x: i for i, x in enumerate(sorted(["Adware", "Benigh", "Banking", "SMS", "Riskware"]))}
        if not base_path.exists():
            raise FileNotFoundError(f'{base_path} does not exist')
        apk_list = sorted([x for x in base_path.iterdir()])
        samples = []
        labels = {}
        for apk in apk_list:
            samples.append(apk.name)
            label = labels_dict[re.findall(r'[A-Z](?:[a-z]|[A-Z])+', apk.name)[0]]
            labels[apk.name] = int(label != 2)
        return samples, labels

    def setup(self, stage=None):
        samples, labels = self.get_samples()
        train_samples, val_samples, test_samples = self.splitter(samples, labels, self.split_ratios)
        self.train_dataset = MalwareDataset(self.data_dir, train_samples, labels)
        self.val_dataset = MalwareDataset(self.data_dir, val_samples, labels)
        self.test_dataset = MalwareDataset(self.data_dir, test_samples, labels)

    def train_dataloader(self):
        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=collate)

    def val_dataloader(self):
        return DataLoader(self.val_dataset, batch_size=self.batch_size, collate_fn=collate)

    def test_dataloader(self):
        return DataLoader(self.test_dataset, batch_size=self.batch_size, collate_fn=collate)
