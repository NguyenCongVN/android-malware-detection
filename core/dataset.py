from pathlib import Path
from typing import List, Dict, Tuple

import torch
import dgl
from scripts.process_dataset import get_api_list
from torch.utils.data import Dataset

attributes = ['external', 'entrypoint', 'native', 'public', 'static', 'codesize']


class MalwareDataset(Dataset):
    def __init__(
            self,
            save_dir: str,
            samples: List[str],
            labels: Dict[str, int],
            cache: bool,
            attribute_list: List[str] = []
    ):
        self.attribute_list = attribute_list
        self.attribute_drop_set = set()
        self.attribute_drop_calculated = False
        self.save_dir = Path(save_dir)
        self.samples = samples
        self.labels = labels
        self.cache: Dict[int, Tuple[dgl.DGLGraph, int]] = {} if cache else None
        self.api_list_length = len(get_api_list())

    def __len__(self) -> int:
        """Denotes the total number of samples"""
        return len(self.samples)

    @torch.no_grad()
    def _process_node_attributes(self, g: dgl.DGLGraph):
        if 'api_package' in g.ndata:
            nodes = torch.arange(len(g.nodes()))
            api_packages = g.ndata['api_package']
            dim_0 = nodes[torch.where(api_packages >= 0)].view(-1, 1)
            dim_1 = api_packages[torch.where(api_packages >= 0)].view(-1, 1)
            indices = torch.cat([dim_0, dim_1], dim=1).t()
            values = torch.ones(len(dim_0))
            size = torch.Size([len(g.nodes()), self.api_list_length])
            g.ndata['api_package'] = torch.sparse.ShortTensor(indices, values, size).to_dense()
        for attribute in attributes:
            if attribute in g.ndata:
                g.ndata[attribute] = g.ndata[attribute].view(-1, 1)
        return g

    def __getitem__(self, index: int) -> Tuple[dgl.DGLGraph, int]:
        """Generates one sample of data"""
        name = self.samples[index].split('.')[0]
        graphs, _ = dgl.data.utils.load_graphs(str(self.save_dir / name))
        graph = dgl.add_self_loop(graphs[0])
        graph.ndata['ex'] = graph.ndata['external']
        if not self.attribute_drop_calculated:
            current_attributes = set(graph.ndata.keys())
            self.attribute_drop_set = current_attributes - set(self.attribute_list) - {'ex'}
        for attribute in self.attribute_drop_set:
            del graph.ndata[attribute]
        value = self._process_node_attributes(graph), self.labels[name]
        if self.cache:
            if index not in self.cache:
                self.cache[index] = value
            else:
                return self.cache[index]
        else:
            return value
